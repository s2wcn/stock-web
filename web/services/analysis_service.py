# æ–‡ä»¶è·¯å¾„: web/services/analysis_service.py
import numpy as np
import pandas as pd
from scipy import stats
from datetime import datetime, timedelta
import akshare as ak
import os
import time
from concurrent.futures import ProcessPoolExecutor
from numba import jit
from typing import Optional, Dict, List, Tuple
from config import StrategyConfig, DingTalkConfig
from logger import analysis_logger as logger
from services.notification_service import DingTalkService

# === Numba åŠ é€Ÿå†…æ ¸ ===
@jit(nopython=True)
def backtest_numba(
    close_arr: np.ndarray, 
    bias5_arr: np.ndarray, 
    bias60_arr: np.ndarray, 
    buy_bias_threshold: float, 
    sell_bias_threshold: float,
    commission: float,      
    initial_capital: float  
) -> Tuple[float, int, int]:
    
    capital = initial_capital
    hold_shares = 0.0
    cost_price = 0.0
    in_market = False
    
    trade_count = 0
    win_count = 0
    n = len(close_arr)
    
    for i in range(n):
        current_price = close_arr[i]
        if current_price <= 0.0001: continue 

        b5 = bias5_arr[i]
        b60 = bias60_arr[i]
        
        if in_market:
            # å–å‡º
            if b5 >= sell_bias_threshold:
                revenue = hold_shares * current_price * (1 - commission)
                current_profit = revenue - (hold_shares * cost_price)
                capital = revenue
                in_market = False
                hold_shares = 0.0
                trade_count += 1
                if current_profit > 0: win_count += 1
        else:
            # ä¹°å…¥
            if b60 <= buy_bias_threshold:
                cost_after_fee = current_price * (1 + commission)
                hold_shares = capital / cost_after_fee
                cost_price = current_price
                in_market = True
                
    final_value = capital
    if in_market:
        final_value = hold_shares * close_arr[-1] * (1 - commission)
        
    return_pct = (final_value - initial_capital) / initial_capital * 100
    return return_pct, trade_count, win_count

def _worker_optimize_stock(doc_data: Dict) -> Optional[Tuple[str, str, Dict]]:
    code = doc_data["_id"]
    qfq_list = doc_data.get("qfq_history", [])
    bull_label = doc_data.get("bull_label", "")
    
    years = 0
    if "5å¹´" in bull_label: years = 5
    elif "4å¹´" in bull_label: years = 4
    elif "3å¹´" in bull_label: years = 3
    elif "2å¹´" in bull_label: years = 2
    elif "1å¹´" in bull_label: years = 1
    
    if years == 0 or not qfq_list: return None

    try:
        df = pd.DataFrame(qfq_list)
        if 'close' not in df.columns: return None
        df['close'] = pd.to_numeric(df['close'], errors='coerce')
        df = df[df['close'] > 0.0001].copy().reset_index(drop=True)
        df['date'] = pd.to_datetime(df['date'])
        
        if len(df) < 100: return None

        close_series = df['close'].astype(float)
        df['ma_short'] = close_series.rolling(window=StrategyConfig.MA_SHORT_WINDOW).mean()
        df['ma_long'] = close_series.rolling(window=StrategyConfig.MA_LONG_WINDOW).mean()
        
        with np.errstate(divide='ignore', invalid='ignore'):
            df['bias_short'] = (close_series - df['ma_short']) / df['ma_short']
            df['bias_long'] = (close_series - df['ma_long']) / df['ma_long']

        latest_date = df['date'].iloc[-1]
        try: target_start = latest_date - pd.DateOffset(years=years)
        except: target_start = latest_date - timedelta(days=365 * years)
        
        mask = df['date'] >= target_start
        if not mask.any(): return None
        start_idx = mask.idxmax()
        
        if start_idx > 0: benchmark_cost = df.iloc[start_idx - 1]['close']
        else: benchmark_cost = df.iloc[start_idx]['open']

        df_slice = df.iloc[start_idx:].copy().reset_index(drop=True)
        df_slice.dropna(subset=['ma_long', 'bias_short', 'bias_long'], inplace=True)
        if df_slice.empty: return None

        close_arr = df_slice['close'].astype(float).values
        bias_short_arr = df_slice['bias_short'].astype(float).values
        bias_long_arr = df_slice['bias_long'].astype(float).values

        benchmark_return = 0.0
        if benchmark_cost > 0.0001:
            benchmark_return = (close_arr[-1] - benchmark_cost) / benchmark_cost * 100

        best_result = {
            "total_return": -999,
            "benchmark_return": round(benchmark_return, 2),
            "params": {"buy_ma60_bias": 0, "sell_ma5_bias": 0},
            "metrics": {"win_rate": 0, "trades": 0}
        }
        
        buy_range = np.arange(*StrategyConfig.STRAT_BUY_RANGE)
        sell_range = np.arange(*StrategyConfig.STRAT_SELL_RANGE)

        for b in buy_range:
            for s in sell_range:
                ret, trades, wins = backtest_numba(
                    close_arr, bias_short_arr, bias_long_arr, float(b), float(s),
                    StrategyConfig.STRAT_COMMISSION,
                    StrategyConfig.STRAT_INITIAL_CAPITAL
                )
                
                if trades < StrategyConfig.MIN_STRAT_TRADES: continue 
                
                if ret > best_result["total_return"]:
                    wr = (wins / trades * 100) if trades > 0 else 0
                    best_result.update({
                        "total_return": round(ret, 2),
                        "params": {
                            "buy_ma60_bias": round(b * 100, 1),
                            "sell_ma5_bias": round(s * 100, 1)
                        },
                        "metrics": {"win_rate": round(wr, 1), "trades": trades}
                    })
        
        if best_result["total_return"] == -999: return None
        return code, doc_data.get("name", ""), best_result

    except Exception: return None

class AnalysisService:
    def __init__(self, db_collection, status_tracker=None):
        self.collection = db_collection
        self.status = status_tracker

    def analyze_trend(self):
        """æ‰§è¡Œé•¿ç‰›è¶‹åŠ¿åˆ†æ (å†…å­˜ä¼˜åŒ–ç‰ˆ)"""
        logger.info("ğŸš€ Service: å¼€å§‹æ‰§è¡Œã€5å¹´é•¿ç‰›åˆ†çº§ç­›é€‰ã€‘(ä¼˜åŒ–å†…å­˜æ¨¡å¼)...")
        
        # [ä¼˜åŒ–ç‚¹ 1] ä»…æŸ¥è¯¢ ID å’Œ åŸºæœ¬ä¿¡æ¯ï¼Œä¸è¦ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å†å²æ•°æ® (qfq_history)
        # å¦åˆ™ 2000 åªè‚¡ç¥¨ * 5å¹´æ•°æ®ä¼šç¬é—´æ’‘çˆ†å†…å­˜
        cursor = self.collection.find({}, {"_id": 1, "name": 1, "latest_data": 1})
        all_basic_docs = list(cursor)
        
        total = len(all_basic_docs)
        if self.status:
            self.status.start(total)
            self.status.message = "æ­£åœ¨è¿›è¡Œè¶‹åŠ¿åˆ†æ..."

        logger.info(f"ğŸ“Š å¾…åˆ†æè‚¡ç¥¨æ•°é‡: {total}")

        for i, basic_doc in enumerate(all_basic_docs):
            if self.status and self.status.should_stop: break
            
            code = basic_doc["_id"]
            if str(code).startswith("8"): continue

            if self.status: self.status.update(i + 1, message=f"åˆ†æ: {basic_doc.get('name')}")
            
            # [ä¼˜åŒ–ç‚¹ 2] æ¯ 20 åªè‚¡ç¥¨å¼ºåˆ¶ä¼‘çœ  0.1 ç§’ï¼Œé‡Šæ”¾ CPU ç»™ Web æœåŠ¡å™¨ï¼Œé˜²æ­¢ç½‘é¡µæ‰“ä¸å¼€
            if i % 20 == 0:
                time.sleep(0.1)

            try:
                # [ä¼˜åŒ–ç‚¹ 3] åªæœ‰åˆ†æåˆ°å½“å‰è¿™åªè‚¡ç¥¨æ—¶ï¼Œæ‰å»æ•°æ®åº“å•ç‹¬æŸ¥å®ƒçš„å†å²æ•°æ®
                # ç”¨å®Œå³ä¸¢ï¼Œä¿è¯å†…å­˜å ç”¨å¹³ç¨³
                full_doc = self.collection.find_one({"_id": code}, {"qfq_history": 1, "latest_data": 1})
                if full_doc:
                    # åˆå¹¶ basic_doc å’Œ full_doc (ä¸»è¦æ˜¯ä¸ºäº†æŠŠ name ä¼ è¿›å»ï¼Œè™½ç„¶ analyze_single_stock ç›®å‰ä¸»è¦ç”¨ history)
                    # _analyze_single_stock éœ€è¦ qfq_history å’Œ latest_data
                    full_doc["name"] = basic_doc.get("name")
                    self._analyze_single_stock(full_doc)
                    
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ†æ {code} å¤±è´¥: {e}")

        logger.info("âœ… Service: è¶‹åŠ¿åˆ†æé˜¶æ®µå®Œæˆ")

    def optimize_strategies(self):
        logger.info("ğŸš€ Service: å¼€å§‹å¯¹é•¿ç‰›è‚¡è¿›è¡Œã€ç­–ç•¥å‚æ•°ä¼˜åŒ–ã€‘...")
        
        # è¿™é‡Œæ•°æ®é‡ç›¸å¯¹è¾ƒå°‘ï¼ˆåªæœ‰è¢«é€‰å‡ºçš„é•¿ç‰›è‚¡ï¼‰ï¼Œå¯ä»¥ç›´æ¥æŸ¥è¯¢
        target_stocks = list(self.collection.find({"bull_label": {"$exists": True}}))
        
        total = len(target_stocks)
        if total == 0: return

        if self.status: self.status.message = f"æ­£åœ¨ä¼˜åŒ– {total} åªé•¿ç‰›è‚¡ç­–ç•¥..."

        updated_count = 0
        with ProcessPoolExecutor(max_workers=min(os.cpu_count(), 4)) as pool:
            results = pool.map(_worker_optimize_stock, target_stocks)
            for res in results:
                if self.status and self.status.should_stop: break
                if res:
                    code, _, strat_data = res
                    self.collection.update_one({"_id": code}, {"$set": {"ma_strategy": strat_data}})
                    updated_count += 1
        
        logger.info(f"âœ… Service: ç­–ç•¥ä¼˜åŒ–å®Œæˆï¼Œæ›´æ–° {updated_count} åª")
        if self.status: self.status.finish("å…¨æµç¨‹åˆ†æå®Œæˆ")

    def check_signals_and_notify(self):
        logger.info("ğŸ”” æ­£åœ¨æ£€æŸ¥ä»Šæ—¥ä¹°å–ä¿¡å·...")
        
        query = {
            "bull_label": {"$exists": True}, 
            "ma_strategy": {"$exists": True},
            "qfq_history": {"$exists": True, "$not": {"$size": 0}}
        }
        # é™åˆ¶å†å²æ•°æ®è¿”å›æ•°é‡ï¼Œåªå–æœ€è¿‘ 100 å¤©
        cursor = self.collection.find(query, {"_id": 1, "name": 1, "bull_label": 1, "ma_strategy": 1, "qfq_history": {"$slice": -100}})
        
        buy_signals = []
        sell_signals = []
        approach_buy_signals = []
        approach_sell_signals = []
        
        for doc in cursor:
            try:
                code = doc["_id"]
                name = doc["name"]
                strategy = doc["ma_strategy"]
                history = doc["qfq_history"]
                
                params = strategy.get("params", {})
                buy_threshold_pct = params.get("buy_ma60_bias") 
                sell_threshold_pct = params.get("sell_ma5_bias") 
                
                if buy_threshold_pct is None or sell_threshold_pct is None: continue
                
                df = pd.DataFrame(history)
                df['close'] = pd.to_numeric(df['close'], errors='coerce')
                df = df.dropna(subset=['close'])
                if len(df) < 60: continue
                
                latest = df.iloc[-1]
                latest_date = pd.to_datetime(latest['date']).strftime("%Y-%m-%d")
                
                if (datetime.now() - datetime.strptime(latest_date, "%Y-%m-%d")).days > 5:
                    continue

                ma5 = df['close'].rolling(5).mean().iloc[-1]
                ma60 = df['close'].rolling(60).mean().iloc[-1]
                close = latest['close']
                
                bias_5_pct = (close - ma5) / ma5 * 100
                bias_60_pct = (close - ma60) / ma60 * 100
                
                if bias_60_pct <= buy_threshold_pct:
                    buy_signals.append(f"- **{name}** ({code}): ç°åç¦» {bias_60_pct:.2f}% (ç ´ {buy_threshold_pct}%) ğŸŸ¢ ä¹°å…¥")
                
                elif (bias_60_pct - buy_threshold_pct) <= abs(buy_threshold_pct * DingTalkConfig.APPROACH_BUFFER):
                    approach_buy_signals.append(f"- {name} ({code}): ç°åç¦» {bias_60_pct:.2f}% (è¿‘ {buy_threshold_pct}%)")

                if bias_5_pct >= sell_threshold_pct:
                    sell_signals.append(f"- **{name}** ({code}): ç°åç¦» {bias_5_pct:.2f}% (ç ´ {sell_threshold_pct}%) ğŸ”´ å–å‡º")
                
                elif (sell_threshold_pct - bias_5_pct) <= abs(sell_threshold_pct * DingTalkConfig.APPROACH_BUFFER):
                    approach_sell_signals.append(f"- {name} ({code}): ç°åç¦» {bias_5_pct:.2f}% (è¿‘ {sell_threshold_pct}%)")

            except Exception as e:
                logger.error(f"ä¿¡å·æ£€æŸ¥å‡ºé”™ {code}: {e}")

        if any([buy_signals, sell_signals, approach_buy_signals, approach_sell_signals]):
            title = "ğŸ“¢ æ¸¯è‚¡é•¿ç‰›ç­–ç•¥ä¿¡å·"
            content = [f"## {title} ({datetime.now().strftime('%m-%d %H:%M')})"]
            
            if buy_signals:
                content.append("\n### ğŸŸ¢ è§¦å‘ä¹°å…¥")
                content.extend(buy_signals)
            
            if sell_signals:
                content.append("\n### ğŸ”´ è§¦å‘å–å‡º")
                content.extend(sell_signals)
                
            if approach_buy_signals:
                content.append("\n#### ğŸ“‰ æ¥è¿‘ä¹°ç‚¹")
                content.extend(approach_buy_signals)

            if approach_sell_signals:
                content.append("\n#### ğŸ“ˆ æ¥è¿‘å–ç‚¹")
                content.extend(approach_sell_signals)
            
            DingTalkService.send_markdown(title, "\n".join(content))
        else:
            logger.info("ğŸ”• ä»Šæ—¥æ— é‡ç‚¹ä¿¡å·è§¦å‘")

    def _analyze_single_stock(self, doc: Dict):
        code = doc["_id"]
        latest = doc.get("latest_data", {})
        mcap = latest.get("æ€»å¸‚å€¼(æ¸¯å…ƒ)")
        roe = latest.get("è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)")

        if (mcap is None or mcap < StrategyConfig.MIN_MARKET_CAP) or (roe is None or roe <= 0):
            self.collection.update_one({"_id": code}, {"$unset": {"bull_label": "", "trend_analysis": ""}})
            return

        # è¿™é‡Œçš„ fetch é€»è¾‘åœ¨ä¼˜åŒ–ç‰ˆ analyze_trend ä¸­å·²ç»é€šè¿‡å•ç‹¬æŸ¥åº“è·å–äº† qfq_history
        # ä½†å¦‚æœæ˜¯å•ä¸ªé‡ç®—è°ƒç”¨ï¼Œå¯èƒ½è¿˜éœ€è¦å…¼å®¹
        qfq_data = doc.get("qfq_history", [])
        
        if not qfq_data:
             try:
                # åªæœ‰å½“æ•°æ®çœŸçš„æ²¡æœ‰æ—¶ï¼Œæ‰å°è¯•è”ç½‘è¡¥æ•‘
                raw_df = ak.stock_hk_daily(symbol=code, adjust="qfq")
                qfq_data = raw_df.to_dict('records') if raw_df is not None else []
             except: pass
        if not qfq_data: return

        df = pd.DataFrame(qfq_data)
        if 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])
        if 'close' in df.columns: df['close'] = df['close'].astype(float)
        
        if 'volume' in df.columns:
            df['amount_est'] = df['close'] * df['volume'].astype(float)
        else:
            df['amount_est'] = 0

        df['trend_short'] = df['close'].rolling(window=StrategyConfig.TREND_MA_SHORT).mean()
        df['trend_long'] = df['close'].rolling(window=StrategyConfig.TREND_MA_LONG).mean()

        if len(df) > StrategyConfig.TREND_BREAK_CHECK_DAYS:
            curr = df.iloc[-1]
            prev_20 = df.iloc[-20]
            if pd.notna(curr['trend_short']) and pd.notna(curr['trend_long']):
                if curr['trend_short'] < curr['trend_long'] and curr['trend_long'] < prev_20['trend_long']:
                    self.collection.update_one({"_id": code}, {"$unset": {"bull_label": "", "trend_analysis": ""}})
                    return

        latest_date = df['date'].iloc[-1]
        bull_label = None
        trend_data = {}

        for year in [5, 4, 3, 2, 1]:
            try: target_start = latest_date - pd.DateOffset(years=year)
            except: target_start = latest_date - timedelta(days=365 * year)
            
            mask = df['date'] >= target_start
            if not mask.any(): continue
            df_sub = df[mask].copy()
            
            if df_sub.empty: continue
            if (df_sub['date'].iloc[0] - target_start).days > 30: continue
            if df_sub['amount_est'].mean() < StrategyConfig.MIN_TURNOVER: continue
            
            if self._check_ma_interruption(df_sub): continue
            
            y_data = df_sub['close'].values
            if len(y_data) < StrategyConfig.MIN_REGRESSION_SAMPLES or np.any(y_data <= 0): continue
            
            start_ts = df_sub['date'].iloc[0]
            x_data = (df_sub['date'] - start_ts).dt.days.values / 365.25
            log_y = np.log(y_data)
            
            slope, intercept, r_value, _, _ = stats.linregress(x_data, log_y)
            r2 = r_value ** 2
            ann_ret = (np.exp(slope) - 1) * 100
            
            if r2 >= StrategyConfig.MIN_R_SQUARED and slope > 0 and \
               StrategyConfig.MIN_ANNUAL_RETURN <= ann_ret <= StrategyConfig.MAX_ANNUAL_RETURN:
                bull_label = f"é•¿ç‰›{year}å¹´"
                trend_data = {
                    "r_squared": round(r2, 4),
                    "annual_return_pct": round(ann_ret, 2),
                    "slope": round(slope, 6),
                    "period_years": year,
                    "avg_turnover": round(df_sub['amount_est'].mean(), 0),
                    "updated_at": datetime.now()
                }
                break

        if bull_label:
            self.collection.update_one({"_id": code}, {"$set": {"bull_label": bull_label, "trend_analysis": trend_data}})
        else:
            self.collection.update_one({"_id": code}, {"$unset": {"bull_label": "", "trend_analysis": ""}})

    def _check_ma_interruption(self, df_subset):
        col_name = 'trend_long'
        valid_ma = df_subset.dropna(subset=[col_name])
        if valid_ma.empty: return True
        is_below = valid_ma['close'] < valid_ma[col_name]
        groups = is_below.ne(is_below.shift()).cumsum()
        consecutive = is_below.groupby(groups).sum()
        return consecutive.max() >= 5