import akshare as ak
import pandas as pd
import time
import random
import math
from datetime import datetime
from database import stock_collection
# å¼•å…¥çŠ¶æ€ç®¡ç† (ç¡®ä¿æ‚¨çš„é¡¹ç›®ä¸­å·²æœ‰ crawler_state.py)
from crawler_state import status

# === 1. å®šä¹‰éœ€è¦æ¸…æ´—ä¸ºæ•°å­—çš„åŸºç¡€å­—æ®µ (åŸæœ‰çš„æ‰€æœ‰å­—æ®µ) ===
NUMERIC_FIELDS = [
    "åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)", "æ¯è‚¡å‡€èµ„äº§(å…ƒ)", "æ³•å®šè‚¡æœ¬(è‚¡)", "æ¯æ‰‹è‚¡", 
    "æ¯è‚¡è‚¡æ¯TTM(æ¸¯å…ƒ)", "æ´¾æ¯æ¯”ç‡(%)", "å·²å‘è¡Œè‚¡æœ¬(è‚¡)", "å·²å‘è¡Œè‚¡æœ¬-Hè‚¡(è‚¡)", 
    "æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)", "è‚¡æ¯ç‡TTM(%)", "æ€»å¸‚å€¼(æ¸¯å…ƒ)", "æ¸¯è‚¡å¸‚å€¼(æ¸¯å…ƒ)", 
    "è¥ä¸šæ€»æ”¶å…¥", "è¥ä¸šæ€»æ”¶å…¥æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "é”€å”®å‡€åˆ©ç‡(%)", "å‡€åˆ©æ¶¦", 
    "å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)", "å¸‚ç›ˆç‡", "PEG", "å¸‚å‡€ç‡", 
    "æ€»èµ„äº§å›æŠ¥ç‡(%)"
]

def get_hk_codes_from_sina():
    print("ğŸ“¡ è¿æ¥æ¥å£è·å–å…¨å¸‚åœºæ¸…å•...")
    try:
        df = ak.stock_hk_spot()
        if df is None or df.empty: return {}
        codes = df['ä»£ç '].astype(str).tolist()
        names = df['ä¸­æ–‡åç§°'].tolist()
        return dict(zip(codes, names))
    except Exception as e:
        print(f"âŒ è·å–åˆ—è¡¨å¤±è´¥: {e}")
        return {}

def fetch_and_save_single_stock(code, name):
    try:
        # 1. æŠ“å–æ•°æ®
        df = ak.stock_hk_financial_indicator_em(symbol=code)
        if df is None or df.empty: return

        # 2. å¯»æ‰¾æ—¥æœŸåˆ—
        date_col = None
        for col in ['æ—¥æœŸ', 'date', 'Date', 'ç»Ÿè®¡æ—¥æœŸ']:
            if col in df.columns:
                date_col = col
                break
        
        if date_col is None:
            today = datetime.now().strftime("%Y-%m-%d")
            df['æ—¥æœŸ'] = today
            date_col = 'æ—¥æœŸ'
            if len(df) > 1: df = df.iloc[[-1]]

        df[date_col] = pd.to_datetime(df[date_col]).dt.strftime("%Y-%m-%d")
        df = df.sort_values(by=date_col)

        # è¯»å–ç°æœ‰æ•°æ®
        existing_doc = stock_collection.find_one({"_id": code})
        history_map = {item["date"]: item for item in existing_doc.get("history", [])} if existing_doc else {}

        latest_record = {}
        
        for _, row in df.iterrows():
            row_date = row[date_col]
            raw_data = row.to_dict()
            new_data = {}
            
            # === åŸºç¡€æ•°æ®æ¸…æ´— (ä¿ç•™æ‰€æœ‰åŸå­—æ®µ) ===
            for k, v in raw_data.items():
                if pd.isna(v): continue
                # å°è¯•å°†æ•°å­—å‹çš„å­—ç¬¦ä¸²(å¦‚ "1,000")è½¬ä¸º float
                if k in NUMERIC_FIELDS:
                    try:
                        new_data[k] = float(str(v).replace(',', ''))
                    except:
                        new_data[k] = v
                else:
                    new_data[k] = v
            
            new_data["date"] = row_date

            # === è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è·å–æµ®ç‚¹æ•° ===
            def get_v(keys):
                for k in keys:
                    if k in new_data and isinstance(new_data[k], (int, float)):
                        return new_data[k]
                return None

            # è·å–è®¡ç®—æ‰€éœ€çš„åŸºç¡€å˜é‡
            pe = get_v(['å¸‚ç›ˆç‡', 'PE'])
            eps = get_v(['åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š'])
            bvps = get_v(['æ¯è‚¡å‡€èµ„äº§(å…ƒ)', 'æ¯è‚¡å‡€èµ„äº§'])
            growth = get_v(['å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)', 'å‡€åˆ©æ¶¦ç¯æ¯”å¢é•¿'])
            dividend_yield = get_v(['è‚¡æ¯ç‡TTM(%)', 'è‚¡æ¯ç‡'])
            ocf_ps = get_v(['æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)', 'æ¯è‚¡ç»è¥ç°é‡‘æµ'])
            roe = get_v(['è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)', 'ROE'])
            roa = get_v(['æ€»èµ„äº§å›æŠ¥ç‡(%)', 'ROA'])
            net_margin = get_v(['é”€å”®å‡€åˆ©ç‡(%)', 'é”€å”®å‡€åˆ©ç‡'])

            # === æ–°å¢å…¬å¼è®¡ç®— ===

            # 0. PEG (åŸæœ‰)
            if "PEG" not in new_data and pe is not None and growth is not None:
                if growth != 0:
                    new_data['PEG'] = round(pe / growth, 4)

            # 1. PEGY Ratio
            if pe is not None and growth is not None and dividend_yield is not None:
                total_return = growth + dividend_yield
                if total_return > 0:
                    new_data['PEGY'] = round(pe / total_return, 4)

            # 2. å½¼å¾—æ—å¥‡ä¼°å€¼
            if growth is not None and dividend_yield is not None:
                new_data['å½¼å¾—æ—å¥‡ä¼°å€¼'] = round(growth + dividend_yield, 2)

            # 3. å‡€ç°æ¯”
            if ocf_ps is not None and eps is not None and eps != 0:
                new_data['å‡€ç°æ¯”'] = round(ocf_ps / eps, 2)

            # 4. å¸‚ç°ç‡ (P/CF)
            if pe is not None and eps is not None and ocf_ps is not None and ocf_ps != 0:
                price = pe * eps
                new_data['å¸‚ç°ç‡'] = round(price / ocf_ps, 2)

            # 5. è´¢åŠ¡æ æ†
            if roe is not None and roa is not None and roa != 0:
                new_data['è´¢åŠ¡æ æ†'] = round(roe / roa, 2)

            # 6. æ€»èµ„äº§å‘¨è½¬ç‡
            if roa is not None and net_margin is not None and net_margin != 0:
                new_data['æ€»èµ„äº§å‘¨è½¬ç‡'] = round(roa / net_margin, 2)

            # 7. æ ¼é›·å„å§†æ•°
            if eps is not None and bvps is not None:
                val = 22.5 * eps * bvps
                if val > 0:
                    new_data['æ ¼é›·å„å§†æ•°'] = round(math.sqrt(val), 2)

            # æ›´æ–°æ•°æ®
            if row_date in history_map:
                history_map[row_date].update(new_data)
            else:
                history_map[row_date] = new_data
            
            latest_record = history_map[row_date]

        sorted_history = sorted(history_map.values(), key=lambda x: x["date"])

        doc = {
            "_id": code,
            "name": name,
            "updated_at": datetime.now(),
            "latest_data": latest_record,
            "history": sorted_history
        }

        stock_collection.replace_one({"_id": code}, doc, upsert=True)

    except Exception as e:
        print(f"âš ï¸ å¤„ç† {code} å¼‚å¸¸: {e}")

def run_crawler_task():
    print(f"[{datetime.now()}] ğŸš€ å¼€å§‹ MongoDB é‡‡é›†ä»»åŠ¡...")
    
    code_map = get_hk_codes_from_sina()
    if not code_map: 
        status.finish()
        return

    # å…¨é‡æŠ“å–
    all_codes = list(code_map.items())
    
    total = len(all_codes)
    print(f"ğŸ“Š æœ¬æ¬¡ä»»åŠ¡å°†æŠ“å– {total} åªè‚¡ç¥¨...")
    
    status.start(total)

    for i, (code, name) in enumerate(all_codes):
        status.update(i + 1, message=f"æ­£åœ¨å¤„ç†: {name}")
        print(f"â³ ({i+1}/{total}) æ­£åœ¨å¤„ç†: {name}")
        fetch_and_save_single_stock(code, name)
        time.sleep(random.uniform(0.5, 1.5))
    
    status.finish()
    print(f"[{datetime.now()}] ğŸ‰ é‡‡é›†å®Œæˆï¼")

if __name__ == "__main__":
    run_crawler_task()