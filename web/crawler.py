import akshare as ak
import pandas as pd
import time
import random
import math
from datetime import datetime
from database import stock_collection
# å¼•å…¥çŠ¶æ€ç®¡ç†
from crawler_state import status

# === 1. å®šä¹‰éœ€è¦æ¸…æ´—ä¸ºæ•°å­—çš„åŸºç¡€å­—æ®µ ===
NUMERIC_FIELDS = [
    "åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)", "æ¯è‚¡å‡€èµ„äº§(å…ƒ)", "æ³•å®šè‚¡æœ¬(è‚¡)", "æ¯æ‰‹è‚¡", 
    "æ¯è‚¡è‚¡æ¯TTM(æ¸¯å…ƒ)", "æ´¾æ¯æ¯”ç‡(%)", "å·²å‘è¡Œè‚¡æœ¬(è‚¡)", "å·²å‘è¡Œè‚¡æœ¬-Hè‚¡(è‚¡)", 
    "æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)", "è‚¡æ¯ç‡TTM(%)", "æ€»å¸‚å€¼(æ¸¯å…ƒ)", "æ¸¯è‚¡å¸‚å€¼(æ¸¯å…ƒ)", 
    "è¥ä¸šæ€»æ”¶å…¥", "è¥ä¸šæ€»æ”¶å…¥æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "é”€å”®å‡€åˆ©ç‡(%)", "å‡€åˆ©æ¶¦", 
    "å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)", "å¸‚ç›ˆç‡", "PEG", "å¸‚å‡€ç‡", 
    "æ€»èµ„äº§å›æŠ¥ç‡(%)",
    # --- æ–°å¢å­—æ®µ ---
    "åŸºæœ¬æ¯è‚¡æ”¶ç›ŠåŒæ¯”å¢é•¿ç‡", "è¥ä¸šæ”¶å…¥åŒæ¯”å¢é•¿ç‡", "è¥ä¸šåˆ©æ¶¦ç‡åŒæ¯”å¢é•¿ç‡"
]

def get_hk_codes_from_sina():
    print("ğŸ“¡ è¿æ¥æ¥å£è·å–å…¨å¸‚åœºæ¸…å•...")
    try:
        df = ak.stock_hk_spot()
        if df is None or df.empty: return {}
        codes = df['ä»£ç '].astype(str).tolist()
        names = df['ä¸­æ–‡åç§°'].tolist()
        return dict(zip(codes, names))
    except Exception as e:
        print(f"âŒ è·å–åˆ—è¡¨å¤±è´¥: {e}")
        return {}

def fetch_and_save_single_stock(code, name):
    try:
        # === 1. ä¸»æ•°æ®ï¼šè´¢åŠ¡æŒ‡æ ‡ ===
        df = ak.stock_hk_financial_indicator_em(symbol=code)
        if df is None or df.empty: return

        # æ ‡å‡†åŒ–ä¸»æ•°æ®çš„æ—¥æœŸåˆ—
        date_col = None
        for col in ['æ—¥æœŸ', 'date', 'Date', 'ç»Ÿè®¡æ—¥æœŸ']:
            if col in df.columns:
                date_col = col
                break
        
        if date_col is None:
            today = datetime.now().strftime("%Y-%m-%d")
            df['æ—¥æœŸ'] = today
            date_col = 'æ—¥æœŸ'
            if len(df) > 1: df = df.iloc[[-1]]

        df[date_col] = pd.to_datetime(df[date_col]).dt.strftime("%Y-%m-%d")
        df.rename(columns={date_col: 'date'}, inplace=True)

        # === 2. æ–°å¢ï¼šè·å–æˆé•¿æ€§æ•°æ® (Time-Series) ===
        try:
            df_growth = ak.stock_hk_growth_comparison_em(symbol=code)
            if df_growth is not None and not df_growth.empty:
                g_date_col = next((c for c in ['æ—¥æœŸ', 'date', 'Date', 'å¹´åº¦'] if c in df_growth.columns), None)
                if g_date_col:
                    df_growth[g_date_col] = pd.to_datetime(df_growth[g_date_col]).dt.strftime("%Y-%m-%d")
                    df_growth.rename(columns={g_date_col: 'date'}, inplace=True)
                    
                    target_growth_cols = ["åŸºæœ¬æ¯è‚¡æ”¶ç›ŠåŒæ¯”å¢é•¿ç‡", "è¥ä¸šæ”¶å…¥åŒæ¯”å¢é•¿ç‡", "è¥ä¸šåˆ©æ¶¦ç‡åŒæ¯”å¢é•¿ç‡"]
                    existing_cols = [c for c in target_growth_cols if c in df_growth.columns]
                    
                    if existing_cols:
                        df = pd.merge(df, df_growth[['date'] + existing_cols], on='date', how='left', suffixes=('', '_dup'))
                        drop_cols = [c for c in df.columns if c.endswith('_dup')]
                        if drop_cols:
                            df.drop(columns=drop_cols, inplace=True)
        except Exception as e:
            pass

        # === 3. æ–°å¢ï¼šè·å–é™æ€ä¿¡æ¯ (è¡Œä¸š & ç®€ä»‹) ===
        industry_val = ""
        intro_val = ""

        try:
            df_profile = ak.stock_hk_company_profile_em(symbol=code)
            if df_profile is not None and not df_profile.empty:
                if "æ‰€å±è¡Œä¸š" in df_profile.columns:
                    industry_val = str(df_profile["æ‰€å±è¡Œä¸š"].iloc[0])
        except Exception:
            pass

        try:
            df_info = ak.stock_individual_basic_info_hk_xq(symbol=code)
            if df_info is not None and not df_info.empty:
                if "comintr" in df_info.columns:
                    intro_val = str(df_info["comintr"].iloc[0])
        except Exception:
            pass

        # === 4. æ•°æ®å¤„ç†ä¸å­˜å‚¨ ===
        df = df.sort_values(by='date')

        existing_doc = stock_collection.find_one({"_id": code})
        history_map = {item["date"]: item for item in existing_doc.get("history", [])} if existing_doc else {}

        latest_record = {}
        
        for _, row in df.iterrows():
            row_date = row['date']
            raw_data = row.to_dict()
            new_data = {}
            
            for k, v in raw_data.items():
                if pd.isna(v): continue
                if k in NUMERIC_FIELDS:
                    try:
                        # æ ¸å¿ƒé€»è¾‘ï¼šä¿æŒ AkShare è¿”å›çš„åŸå§‹æ•°å€¼
                        # å¦‚æœ AkShare è¿”å› 15.5 (ä»£è¡¨ 15.5%)ï¼Œè¿™é‡Œå­˜å‚¨ä¸º 15.5
                        # è¿™ä¿è¯äº†åç»­ PEG è®¡ç®— (PE/Growth) æ˜¯ PE/15.5ï¼Œç¬¦åˆé€šå¸¸çš„ PEG å®šä¹‰
                        new_data[k] = float(str(v).replace(',', ''))
                    except:
                        new_data[k] = v
                else:
                    new_data[k] = v
            
            if industry_val: new_data['æ‰€å±è¡Œä¸š'] = industry_val
            if intro_val: new_data['ä¼ä¸šç®€ä»‹'] = intro_val
            
            new_data["date"] = row_date

            # === è®¡ç®—è¡ç”ŸæŒ‡æ ‡ ===
            def get_v(keys):
                for k in keys:
                    if k in new_data and isinstance(new_data[k], (int, float)):
                        return new_data[k]
                return None

            pe = get_v(['å¸‚ç›ˆç‡', 'PE'])
            eps = get_v(['åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š'])
            bvps = get_v(['æ¯è‚¡å‡€èµ„äº§(å…ƒ)', 'æ¯è‚¡å‡€èµ„äº§'])
            growth = get_v(['å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)', 'å‡€åˆ©æ¶¦ç¯æ¯”å¢é•¿'])
            dividend_yield = get_v(['è‚¡æ¯ç‡TTM(%)', 'è‚¡æ¯ç‡'])
            ocf_ps = get_v(['æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)', 'æ¯è‚¡ç»è¥ç°é‡‘æµ'])
            roe = get_v(['è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)', 'ROE'])
            roa = get_v(['æ€»èµ„äº§å›æŠ¥ç‡(%)', 'ROA'])
            net_margin = get_v(['é”€å”®å‡€åˆ©ç‡(%)', 'é”€å”®å‡€åˆ©ç‡'])

            # PEG: PE / Growth
            # å‡è®¾ PE=20, Growth=10 (å³ 10%) -> 20/10 = 2.0
            if "PEG" not in new_data and pe is not None and growth is not None:
                if growth != 0:
                    new_data['PEG'] = round(pe / growth, 4)

            # PEGY: PE / (Growth + Yield)
            # å‡è®¾ Yield=5 (å³ 5%) -> 20 / (10 + 5) = 1.33
            if pe is not None and growth is not None and dividend_yield is not None:
                total_return = growth + dividend_yield
                if total_return > 0:
                    new_data['PEGY'] = round(pe / total_return, 4)

            # å½¼å¾—æ—å¥‡ä¼°å€¼: Growth + Yield -> 15 (15%)
            if growth is not None and dividend_yield is not None:
                new_data['å½¼å¾—æ—å¥‡ä¼°å€¼'] = round(growth + dividend_yield, 2)

            if ocf_ps is not None and eps is not None and eps != 0:
                new_data['å‡€ç°æ¯”'] = round(ocf_ps / eps, 2)

            if pe is not None and eps is not None and ocf_ps is not None and ocf_ps != 0:
                price = pe * eps
                new_data['å¸‚ç°ç‡'] = round(price / ocf_ps, 2)

            if roe is not None and roa is not None and roa != 0:
                new_data['è´¢åŠ¡æ æ†'] = round(roe / roa, 2)

            if roa is not None and net_margin is not None and net_margin != 0:
                new_data['æ€»èµ„äº§å‘¨è½¬ç‡'] = round(roa / net_margin, 2)

            if eps is not None and bvps is not None:
                val = 22.5 * eps * bvps
                if val > 0:
                    new_data['æ ¼é›·å„å§†æ•°'] = round(math.sqrt(val), 2)

            if row_date in history_map:
                history_map[row_date].update(new_data)
            else:
                history_map[row_date] = new_data
            
            latest_record = history_map[row_date]

        sorted_history = sorted(history_map.values(), key=lambda x: x["date"])

        doc = {
            "_id": code,
            "name": name,
            "updated_at": datetime.now(),
            "latest_data": latest_record,
            "history": sorted_history,
            "industry": industry_val,
            "intro": intro_val
        }

        stock_collection.replace_one({"_id": code}, doc, upsert=True)

    except Exception as e:
        print(f"âš ï¸ å¤„ç† {code} å¼‚å¸¸: {e}")

def run_crawler_task():
    print(f"[{datetime.now()}] ğŸš€ å¼€å§‹ MongoDB é‡‡é›†ä»»åŠ¡...")
    
    code_map = get_hk_codes_from_sina()
    if not code_map: 
        status.finish()
        return

    all_codes = list(code_map.items())
    total = len(all_codes)
    print(f"ğŸ“Š æœ¬æ¬¡ä»»åŠ¡å°†æŠ“å– {total} åªè‚¡ç¥¨...")
    
    status.start(total)

    for i, (code, name) in enumerate(all_codes):
        status.update(i + 1, message=f"æ­£åœ¨å¤„ç†: {name}")
        fetch_and_save_single_stock(code, name)
        time.sleep(random.uniform(1.0, 2.0))
    
    status.finish()
    print(f"[{datetime.now()}] ğŸ‰ é‡‡é›†å®Œæˆï¼")

if __name__ == "__main__":
    run_crawler_task()