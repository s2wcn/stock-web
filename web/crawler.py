import akshare as ak
import pandas as pd
import time
import random
from datetime import datetime
from database import stock_collection

# å®šä¹‰éœ€è¦é‡ç‚¹é‡‡é›†å’Œæ¸…æ´—çš„æ•°å­—å‹å­—æ®µåˆ—è¡¨
NUMERIC_FIELDS = [
    "åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)", "æ¯è‚¡å‡€èµ„äº§(å…ƒ)", "æ³•å®šè‚¡æœ¬(è‚¡)", "æ¯æ‰‹è‚¡", 
    "æ¯è‚¡è‚¡æ¯TTM(æ¸¯å…ƒ)", "æ´¾æ¯æ¯”ç‡(%)", "å·²å‘è¡Œè‚¡æœ¬(è‚¡)", "å·²å‘è¡Œè‚¡æœ¬-Hè‚¡(è‚¡)", 
    "æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)", "è‚¡æ¯ç‡TTM(%)", "æ€»å¸‚å€¼(æ¸¯å…ƒ)", "æ¸¯è‚¡å¸‚å€¼(æ¸¯å…ƒ)", 
    "è¥ä¸šæ€»æ”¶å…¥", "è¥ä¸šæ€»æ”¶å…¥æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "é”€å”®å‡€åˆ©ç‡(%)", "å‡€åˆ©æ¶¦", 
    "å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)", "è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)", "å¸‚ç›ˆç‡", "PEG", "å¸‚å‡€ç‡", 
    "æ€»èµ„äº§å›æŠ¥ç‡(%)"
]

def get_hk_codes_from_sina():
    """è·å–æ‰€æœ‰æ¸¯è‚¡ä»£ç """
    print("ğŸ“¡ è¿æ¥æ–°æµªæ¥å£è·å–å…¨å¸‚åœºæ¸…å•...")
    try:
        df = ak.stock_hk_spot()
        if df is None or df.empty: return {}
        codes = df['ä»£ç '].astype(str).tolist()
        names = df['ä¸­æ–‡åç§°'].tolist()
        return dict(zip(codes, names))
    except Exception as e:
        print(f"âŒ è·å–åˆ—è¡¨å¤±è´¥: {e}")
        return {}

def fetch_and_save_single_stock(code, name):
    try:
        # 1. æŠ“å–æ•°æ®
        df = ak.stock_hk_financial_indicator_em(symbol=code)
        if df is None or df.empty: return

        # 2. åŠ¨æ€å¯»æ‰¾æ—¥æœŸåˆ—
        date_col = None
        for col in ['æ—¥æœŸ', 'date', 'Date', 'ç»Ÿè®¡æ—¥æœŸ']:
            if col in df.columns:
                date_col = col
                break
        
        if date_col is None:
            today = datetime.now().strftime("%Y-%m-%d")
            df['æ—¥æœŸ'] = today
            date_col = 'æ—¥æœŸ'
            if len(df) > 1: df = df.iloc[[-1]]

        # ç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²æ—¥æœŸ
        df[date_col] = pd.to_datetime(df[date_col]).dt.strftime("%Y-%m-%d")
        df = df.sort_values(by=date_col)

        # === è¯»å–ç°æœ‰æ–‡æ¡£ ===
        existing_doc = stock_collection.find_one({"_id": code})
        if existing_doc:
            history_list = existing_doc.get("history", [])
            history_map = {item["date"]: item for item in history_list}
        else:
            history_map = {}

        latest_record = {}
        
        for _, row in df.iterrows():
            row_date = row[date_col]
            
            # è½¬å­—å…¸
            raw_data = row.to_dict()
            new_data = {}
            
            # === æ•°æ®æ¸…æ´—æ ¸å¿ƒé€»è¾‘ ===
            for k, v in raw_data.items():
                if pd.isna(v): continue
                
                # å¦‚æœå­—æ®µåœ¨æˆ‘ä»¬éœ€è¦é‡‡é›†çš„æ•°å­—åˆ—è¡¨ä¸­ï¼Œå°è¯•è½¬æ¢
                if k in NUMERIC_FIELDS:
                    try:
                        # å»æ‰é€—å·å¹¶è½¬float
                        val_str = str(v).replace(',', '')
                        new_data[k] = float(val_str)
                    except:
                        # è½¬æ¢å¤±è´¥åˆ™ä¿ç•™åŸå€¼
                        new_data[k] = v
                else:
                    new_data[k] = v
            
            new_data["date"] = row_date

            # è¡¥å……è®¡ç®—é€»è¾‘ï¼šå¦‚æœæ¥å£æ²¡è¿”å› PEGï¼Œå°è¯•æ‰‹åŠ¨è®¡ç®—
            # (AkShare å¾ˆå¤šæ—¶å€™ä¸ç›´æ¥è¿”å› PEGï¼Œæˆ–è€…å­—æ®µåä¸ä¸€è‡´ï¼Œè¿™é‡Œä¿ç•™å…œåº•é€»è¾‘)
            if "PEG" not in new_data:
                try:
                    pe = new_data.get("å¸‚ç›ˆç‡", new_data.get("PE"))
                    growth = new_data.get("å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)") # ä½¿ç”¨æ–°é‡‡é›†çš„å­—æ®µ
                    
                    if pe and growth:
                        if growth != 0:
                            new_data['PEG'] = round(pe / growth, 4)
                except:
                    pass

            # æ›´æ–°æˆ–æ–°å¢
            if row_date in history_map:
                history_map[row_date].update(new_data)
            else:
                history_map[row_date] = new_data
            
            latest_record = history_map[row_date]

        sorted_history = sorted(history_map.values(), key=lambda x: x["date"])

        doc = {
            "_id": code,
            "name": name,
            "updated_at": datetime.now(),
            "latest_data": latest_record,
            "history": sorted_history
        }

        stock_collection.replace_one({"_id": code}, doc, upsert=True)

    except Exception as e:
        print(f"âš ï¸ å¤„ç† {code} å¼‚å¸¸: {e}")

def run_crawler_task():
    print(f"[{datetime.now()}] ğŸš€ å¼€å§‹ MongoDB é‡‡é›†ä»»åŠ¡ (æµ‹è¯•æ¨¡å¼: å‰10ä¸ª)...")
    code_map = get_hk_codes_from_sina()
    if not code_map: return

    # æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒè¯·å»æ‰ [:10]
    all_codes = list(code_map.items())
    total = len(all_codes)
    print(f"ğŸ“Š æœ¬æ¬¡ä»»åŠ¡å°†æŠ“å– {total} åªè‚¡ç¥¨...")

    for i, (code, name) in enumerate(all_codes):
        print(f"â³ ({i+1}/{total}) æ­£åœ¨å¤„ç†: {name}")
        fetch_and_save_single_stock(code, name)
        time.sleep(random.uniform(10, 20))
    
    print(f"[{datetime.now()}] ğŸ‰ é‡‡é›†å®Œæˆï¼")

if __name__ == "__main__":
    run_crawler_task()