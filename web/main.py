import uvicorn
import importlib
import sys
import os
import time
import math
import random
import pandas as pd
import numpy as np
from fastapi import FastAPI, Request, BackgroundTasks, Body
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from datetime import datetime
from tzlocal import get_localzone 

import akshare as ak

# å¼•å…¥æ•°æ®åº“é›†åˆ
from database import stock_collection, config_collection, template_collection
import crawler_hk as crawler
from crawler_state import status 

# å¼•å…¥åˆ†ææœåŠ¡
from services.analysis_service import AnalysisService
# å¼•å…¥é…ç½®ä¸­çš„å­—æ®µå®šä¹‰
from config import COLUMN_CONFIG, NUMERIC_FIELDS

# åˆå§‹åŒ–è°ƒåº¦å™¨
scheduler = BackgroundScheduler(timezone=str(get_localzone()))
analysis_service = AnalysisService(stock_collection, status)

# é»˜è®¤å®šæ—¶é…ç½®
DEFAULT_SCHEDULE = {
    "type": "daily",      
    "day_of_week": "5",   
    "hour": 17, 
    "minute": 0
}

# === ä»»åŠ¡é€»è¾‘åŒºåŸŸ ===

def analyze_trend_task():
    # ä»£ç†ç»™ Service å¤„ç†
    analysis_service.analyze_trend()

# åŠ¨æ€ä»»åŠ¡åŒ…è£…å™¨
def dynamic_task_wrapper():
    if not status.is_running:
        try:
            print("ğŸ”„ çƒ­åŠ è½½çˆ¬è™«æ¨¡å—...")
            importlib.reload(crawler)
            
            # 1. è¿è¡Œçˆ¬è™«
            crawler.run_crawler_task()
            
            # 2. çˆ¬è™«å®Œæˆåï¼Œè‡ªåŠ¨è¿è¡Œè¶‹åŠ¿åˆ†æ
            if not status.should_stop:
                print("ğŸ”— çˆ¬è™«ç»“æŸï¼Œè‡ªåŠ¨å¯åŠ¨è¶‹åŠ¿åˆ†æ...")
                analyze_trend_task()
                
        except Exception as e:
            print(f"âŒ ä»»åŠ¡å‡ºé”™: {e}")
            status.finish(f"ä»»åŠ¡å¼‚å¸¸: {e}")

def recalculate_db_task():
    print("ğŸ”„ å¼€å§‹æ‰§è¡Œç¦»çº¿è¡¥å…¨æŒ‡æ ‡ä¸ç±»å‹ä¿®å¤...")
    cursor = stock_collection.find({})
    all_docs = list(cursor) 
    total = len(all_docs)
    status.start(total)
    status.message = "æ­£åœ¨è¯»å–æ•°æ®åº“..."

    for i, doc in enumerate(all_docs):
        if status.should_stop:
            status.finish("è¡¥å…¨ä»»åŠ¡å·²ç»ˆæ­¢")
            return

        code = doc["_id"]
        if code.startswith("8"):
             stock_collection.delete_one({"_id": code})
             continue

        name = doc["name"]
        status.update(i + 1, message=f"æ­£åœ¨æ¸…æ´—é‡ç®—: {name}")
        
        history = doc.get("history", [])
        if not history: continue
        
        updated_history = []
        latest_record = {}

        for item in history:
            # [ä¿®å¤] å¼ºåˆ¶ç±»å‹è½¬æ¢ï¼šéå†æ‰€æœ‰é”®ï¼Œå¦‚æœåº”è¯¥ä¸ºæ•°å­—ä½†å´æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•ä¿®å¤
            # è¿™è§£å†³äº†å†å²æ•°æ®ä¸­å¯èƒ½å­˜åœ¨çš„ "15.2" å­—ç¬¦ä¸²é—®é¢˜
            for k, v in item.items():
                if k in NUMERIC_FIELDS and isinstance(v, str):
                    try:
                        item[k] = float(v.replace(',', ''))
                    except:
                        pass # æ— æ³•è½¬æ¢åˆ™ä¿æŒåŸæ ·

            def get_f(keys):
                for k in keys:
                    val = item.get(k)
                    if val is not None:
                        try:
                            # å·²ç»å°è¯•è¿‡ä¿®å¤ï¼Œè¿™é‡Œå†æ¬¡ç¡®ä¿å®‰å…¨
                            return float(str(val).replace(',', ''))
                        except:
                            pass
                return None

            pe = get_f(['å¸‚ç›ˆç‡', 'PE'])
            eps = get_f(['åŸºæœ¬æ¯è‚¡æ”¶ç›Š(å…ƒ)', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š'])
            bvps = get_f(['æ¯è‚¡å‡€èµ„äº§(å…ƒ)', 'æ¯è‚¡å‡€èµ„äº§'])
            growth = get_f(['å‡€åˆ©æ¶¦æ»šåŠ¨ç¯æ¯”å¢é•¿(%)', 'å‡€åˆ©æ¶¦ç¯æ¯”å¢é•¿'])
            div_yield = get_f(['è‚¡æ¯ç‡TTM(%)', 'è‚¡æ¯ç‡'])
            ocf_ps = get_f(['æ¯è‚¡ç»è¥ç°é‡‘æµ(å…ƒ)', 'æ¯è‚¡ç»è¥ç°é‡‘æµ'])
            roe = get_f(['è‚¡ä¸œæƒç›Šå›æŠ¥ç‡(%)', 'ROE'])
            roa = get_f(['æ€»èµ„äº§å›æŠ¥ç‡(%)', 'ROA'])
            net_margin = get_f(['é”€å”®å‡€åˆ©ç‡(%)', 'é”€å”®å‡€åˆ©ç‡'])

            derived_keys = [
                'PEG', 'PEGY', 'å½¼å¾—æ—å¥‡ä¼°å€¼', 'å‡€ç°æ¯”', 'å¸‚ç°ç‡', 
                'è´¢åŠ¡æ æ†', 'æ€»èµ„äº§å‘¨è½¬ç‡', 'æ ¼é›·å„å§†æ•°', 'åˆç†è‚¡ä»·'
            ]
            for key in derived_keys:
                item.pop(key, None)

            if pe and pe > 0 and growth and growth != 0:
                item['PEG'] = round(pe / growth, 4)

            if pe and pe > 0 and growth is not None and div_yield is not None:
                total_return = growth + div_yield
                if total_return > 0:
                    item['PEGY'] = round(pe / total_return, 4)
            
            if eps is not None and growth is not None:
                fair_price = eps * (8.5 + 2 * growth)
                if fair_price > 0:
                    item['åˆç†è‚¡ä»·'] = round(fair_price, 2)
            
            if ocf_ps is not None and eps and eps > 0:
                item['å‡€ç°æ¯”'] = round(ocf_ps / eps, 2)
            
            if pe and pe > 0 and eps and eps > 0 and ocf_ps and ocf_ps != 0:
                price = pe * eps
                item['å¸‚ç°ç‡'] = round(price / ocf_ps, 2)

            if roe is not None and roa and roa != 0:
                item['è´¢åŠ¡æ æ†'] = round(roe / roa, 2)

            if roa is not None and net_margin and net_margin != 0:
                item['æ€»èµ„äº§å‘¨è½¬ç‡'] = round(roa / net_margin, 2)

            if eps is not None and bvps is not None:
                val = 22.5 * eps * bvps
                if val > 0:
                    item['æ ¼é›·å„å§†æ•°'] = round(math.sqrt(val), 2)
            
            updated_history.append(item)
            latest_record = item

        stock_collection.update_one(
            {"_id": code},
            {"$set": {"history": updated_history, "latest_data": latest_record}}
        )

    status.finish("å…¨åº“æ¸…æ´—é‡ç®—å®Œæˆ")

# === è°ƒåº¦å™¨é€»è¾‘ ===
def update_scheduler_job(config: dict):
    try:
        hour = config.get('hour', 17)
        minute = config.get('minute', 0)
        sched_type = config.get('type', 'daily')
        day_of_week = config.get('day_of_week', '5')
        
        local_tz = str(get_localzone())

        if scheduler.get_job('crawler_job'):
            scheduler.remove_job('crawler_job')
        
        if sched_type == 'weekly':
            trigger = CronTrigger(day_of_week=int(day_of_week), hour=hour, minute=minute, timezone=local_tz)
        else:
            trigger = CronTrigger(hour=hour, minute=minute, timezone=local_tz)

        scheduler.add_job(dynamic_task_wrapper, trigger, id='crawler_job')
        return True
    except Exception as e:
        print(f"âŒ æ›´æ–°å®šæ—¶ä»»åŠ¡å¤±è´¥: {e}")
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    config = config_collection.find_one({"_id": "schedule_config"})
    if not config:
        config = DEFAULT_SCHEDULE
        config_collection.insert_one({"_id": "schedule_config", **DEFAULT_SCHEDULE})
    
    update_scheduler_job(config)
    scheduler.start()
    
    yield
    scheduler.shutdown()

app = FastAPI(lifespan=lifespan)
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# === è·¯ç”±åŒºåŸŸ ===

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    # è·å–æœ€åæ›´æ–°æ—¶é—´
    last_time = status.last_finished_time
    if not last_time:
        try:
            latest_doc = stock_collection.find_one(sort=[("updated_at", -1)])
            if latest_doc and "updated_at" in latest_doc:
                last_time = latest_doc["updated_at"]
        except:
            pass
    last_time_str = last_time.strftime("%Y-%m-%d %H:%M") if last_time else "ä»æœª"

    return templates.TemplateResponse("index.html", {
        "request": request, 
        "columns": COLUMN_CONFIG,
        "last_updated": last_time_str
    })

# === [ä¿®æ”¹] é€šç”¨åˆ†é¡µæŸ¥è¯¢æ¥å£ (ä¿®å¤é•¿ç‰›è¯„çº§ç­›é€‰ Bug) ===
@app.post("/api/stocks/query")
async def query_stocks(
    page: int = Body(1), 
    page_size: int = Body(50), 
    sort_key: str = Body(None), 
    sort_dir: str = Body("asc"),
    filters: dict = Body(None),
    search: str = Body(None)
):
    query = {}
    
    # 1. æœç´¢
    if search:
        query["$or"] = [
            {"_id": {"$regex": search, "$options": "i"}},
            {"name": {"$regex": search, "$options": "i"}}
        ]
    
    # 2. ç­›é€‰
    if filters:
        filter_conditions = []
        for key, range_val in filters.items():
            db_key = key
            
            # å­—æ®µæ˜ å°„é€»è¾‘
            if key == "code":
                db_key = "_id"
            elif key.startswith("trend_analysis."):
                db_key = key 
            elif key.startswith("ma_strategy."): 
                db_key = key
            elif key == "bull_label":
                db_key = "bull_label" 
            elif key == "æ‰€å±è¡Œä¸š":
                db_key = "latest_data.æ‰€å±è¡Œä¸š"
            elif key not in ["_id", "name", "bull_label"]:
                # å…¶ä»–é»˜è®¤éƒ½åœ¨ latest_data ä¸‹
                db_key = f"latest_data.{key}"

            min_v = range_val.get("min")
            max_v = range_val.get("max")
            
            range_query = {}
            
            # === [æ ¸å¿ƒä¿®å¤] é’ˆå¯¹ "bull_label" çš„ç‰¹æ®Šæ•°å€¼èŒƒå›´å¤„ç† ===
            if key == "bull_label":
                # å°è¯•åˆ¤æ–­ç”¨æˆ·æ˜¯å¦è¾“å…¥äº†æ•°å­—èŒƒå›´ (ä¾‹å¦‚ 1-5)
                try:
                    target_labels = []
                    # å¦‚æœæœ‰ min æˆ– maxï¼Œå°è¯•è§£æå¹´ä»½
                    start_year = int(float(min_v)) if (min_v is not None and min_v != "") else 1
                    end_year = int(float(max_v)) if (max_v is not None and max_v != "") else 5
                    
                    # ç”ŸæˆåŒ¹é…åˆ—è¡¨ï¼Œä¾‹å¦‚ 3-5 -> ["é•¿ç‰›3å¹´", "é•¿ç‰›4å¹´", "é•¿ç‰›5å¹´"]
                    # å‡è®¾ç³»ç»Ÿç›®å‰æ”¯æŒ 1 åˆ° 5 å¹´
                    for y in range(1, 6):
                        if start_year <= y <= end_year:
                            target_labels.append(f"é•¿ç‰›{y}å¹´")
                    
                    if target_labels:
                        filter_conditions.append({db_key: {"$in": target_labels}})
                    continue # å¤„ç†å®Œæ¯•ï¼Œè·³è¿‡åç»­é€»è¾‘
                    
                except ValueError:
                    # å¦‚æœè¾“å…¥çš„ä¸æ˜¯æ•°å­—ï¼ˆæ¯”å¦‚è¾“å…¥äº†æ–‡æœ¬ "é•¿ç‰›"ï¼‰ï¼Œåˆ™å›é€€åˆ°ä¸‹é¢çš„æ¨¡ç³ŠåŒ¹é…é€»è¾‘
                    pass

            # é’ˆå¯¹æ–‡æœ¬å­—æ®µçš„æ¨¡ç³ŠåŒ¹é… (è¡Œä¸šã€æˆ–è€…éæ•°å­—çš„é•¿ç‰›æœç´¢)
            if key in ["æ‰€å±è¡Œä¸š", "bull_label"]:
                if min_v: 
                    range_query = {"$regex": str(min_v), "$options": "i"}
                    filter_conditions.append({db_key: range_query})
                continue 

            # [ä¿®å¤] å¥å£®çš„æ•°å€¼èŒƒå›´é€»è¾‘ï¼Œé˜²æ­¢éæ•°å­—ç­›é€‰å¯¼è‡´å´©æºƒ
            if min_v is not None and min_v != "":
                try:
                    range_query["$gte"] = float(min_v)
                except ValueError:
                    pass # å¿½ç•¥éæ•°å­—è¾“å…¥
            
            if max_v is not None and max_v != "":
                try:
                    range_query["$lte"] = float(max_v)
                except ValueError:
                    pass

            if range_query:
                cond = {db_key: range_query}
                filter_conditions.append(cond)
        
        if filter_conditions:
            if "$or" in query:
                query = {"$and": [query, *filter_conditions]}
            else:
                if len(filter_conditions) == 1:
                    query.update(filter_conditions[0])
                else:
                    query["$and"] = filter_conditions

    # 3. æ’åº
    sort_stage = [("_id", 1)]
    if sort_key:
        db_sort_key = sort_key
        
        # æ’åºå­—æ®µæ˜ å°„
        if sort_key == "code":
            db_sort_key = "_id"
        elif sort_key not in ["_id", "name", "bull_label"] and not sort_key.startswith("trend_analysis") and not sort_key.startswith("ma_strategy"):
             db_sort_key = f"latest_data.{sort_key}"
             
        direction = 1 if sort_dir == "asc" else -1
        sort_stage = [(db_sort_key, direction)]

    # 4. æ‰§è¡Œ
    total_count = stock_collection.count_documents(query)
    cursor = stock_collection.find(query).sort(sort_stage).skip((page - 1) * page_size).limit(page_size)
    
    data = []
    for doc in cursor:
        latest = doc.get('latest_data', {})
        trend = doc.get("trend_analysis", {})
        ma_strat = doc.get("ma_strategy", {}) 
        
        # æ‰å¹³åŒ–å¤„ç†
        item = {
            "code": doc["_id"],
            "name": doc["name"],
            "date": latest.get("date", "-"),
            "intro": doc.get("intro") or latest.get("ä¼ä¸šç®€ä»‹", ""),
            "is_ggt": doc.get("is_ggt", False),
            "bull_label": doc.get("bull_label", ""),
            **latest 
        }
        for k, v in trend.items():
            item[f"trend_analysis.{k}"] = v

        if ma_strat:
            item["ma_strategy.total_return"] = ma_strat.get("total_return")
            item["ma_strategy.benchmark_return"] = ma_strat.get("benchmark_return")
            
            params = ma_strat.get("params", {})
            item["ma_strategy.buy_bias"] = params.get("buy_ma20_bias")
            item["ma_strategy.sell_bias"] = params.get("sell_ma5_bias")
            
            metrics = ma_strat.get("metrics", {})
            item["ma_strategy.win_rate"] = metrics.get("win_rate")
            item["ma_strategy.trades"] = metrics.get("trades")
            
        data.append(item)

    return {
        "total": total_count,
        "page": page,
        "page_size": page_size,
        "data": data
    }

@app.get("/api/history/{code}")
async def get_history(code: str):
    doc = stock_collection.find_one({"_id": code})
    if not doc:
        return {"name": code, "history": []}
    return {"name": doc["name"], "history": doc.get("history", [])}

@app.get("/api/trigger_crawl")
async def trigger_crawl():
    if status.is_running:
        return {"success": False, "message": "ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·å‹¿é‡å¤è§¦å‘"}
    scheduler.add_job(dynamic_task_wrapper)
    return {"success": True, "message": "åå°ä»»åŠ¡å·²å¯åŠ¨ (çˆ¬è™« + è‡ªåŠ¨è¶‹åŠ¿åˆ†æ)"}

@app.post("/api/stop_crawl")
async def stop_crawl():
    if not status.is_running:
        return {"success": False, "message": "å½“å‰æ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡"}
    status.request_stop()
    return {"success": True, "message": "æ­£åœ¨ç»ˆæ­¢ä»»åŠ¡ï¼Œè¯·ç¨å€™..."}

@app.post("/api/recalculate")
async def trigger_recalculate(background_tasks: BackgroundTasks):
    if status.is_running:
        return {"success": False, "message": "åå°å·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œè¯·ç¨å€™..."}
    background_tasks.add_task(recalculate_db_task)
    return {"success": True, "message": "å·²å¼€å§‹è¡¥å…¨è®¡ç®—ï¼Œè¯·ç•™æ„å³ä¸Šè§’è¿›åº¦æ¡"}

@app.get("/api/status")
async def get_status():
    return {
        "is_running": status.is_running,
        "current": status.current,
        "total": status.total,
        "message": status.message
    }

def restart_program():
    time.sleep(0.5) 
    current_file = os.path.abspath(__file__)
    if os.path.exists(current_file):
        os.utime(current_file, None)

@app.post("/api/restart")
async def restart_service(background_tasks: BackgroundTasks):
    background_tasks.add_task(restart_program)
    return {"success": True, "message": "æœåŠ¡æ­£åœ¨é‡è½½ï¼Œé¡µé¢å°†åœ¨ 3 ç§’ååˆ·æ–°..."}

@app.get("/api/schedule")
async def get_schedule():
    config = config_collection.find_one({"_id": "schedule_config"})
    if not config:
        config = DEFAULT_SCHEDULE
    if "type" not in config: config["type"] = "daily"
    if "day_of_week" not in config: config["day_of_week"] = "5"
    return {
        "type": config.get("type"),
        "day_of_week": config.get("day_of_week"),
        "hour": config.get("hour"),
        "minute": config.get("minute")
    }

@app.post("/api/schedule")
async def set_schedule(data: dict = Body(...)):
    hour = int(data.get("hour"))
    minute = int(data.get("minute"))
    sched_type = data.get("type", "daily")
    day_of_week = str(data.get("day_of_week", "5"))
    
    new_config = {
        "type": sched_type,
        "day_of_week": day_of_week,
        "hour": hour,
        "minute": minute
    }

    config_collection.update_one(
        {"_id": "schedule_config"},
        {"$set": new_config},
        upsert=True
    )
    
    if update_scheduler_job(new_config):
        week_map = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
        desc = f"æ¯å¤© {hour:02d}:{minute:02d}" if sched_type == 'daily' else f"æ¯å‘¨{week_map[int(day_of_week)]} {hour:02d}:{minute:02d}"
        return {"success": True, "message": f"å®šæ—¶ä»»åŠ¡å·²æ›´æ–°: {desc}"}
    else:
        return {"success": False, "message": "è°ƒåº¦å™¨æ›´æ–°å¤±è´¥"}

@app.get("/api/templates")
async def get_templates():
    cursor = template_collection.find({}, {"_id": 0}).sort("name", 1)
    return list(cursor)

@app.post("/api/templates")
async def save_template(data: dict = Body(...)):
    name = data.get("name")
    filters = data.get("filters")
    if not name or not name.strip(): return {"success": False, "message": "æ¨¡ç‰ˆåç§°ä¸èƒ½ä¸ºç©º"}
    if not filters: return {"success": False, "message": "æ¨¡ç‰ˆå†…å®¹ä¸èƒ½ä¸ºç©º"}
    
    template_collection.replace_one(
        {"name": name.strip()}, 
        {"name": name.strip(), "filters": filters}, 
        upsert=True
    )
    return {"success": True, "message": "æ¨¡ç‰ˆå·²ä¿å­˜"}

@app.delete("/api/templates/{name}")
async def delete_template(name: str):
    result = template_collection.delete_one({"name": name})
    if result.deleted_count > 0:
        return {"success": True, "message": "æ¨¡ç‰ˆå·²åˆ é™¤"}
    else:
        return {"success": False, "message": "æ¨¡ç‰ˆä¸å­˜åœ¨"}

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)